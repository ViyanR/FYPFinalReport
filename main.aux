\relax 
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\babel@aux{english}{}
\citation{chahineRobustFlightNavigation2023}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{7}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\citation{hasaniLiquidTimeconstantNetworks2021}
\citation{tedxtalksLiquidNeuralNetworks2023}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Background and Literature Review}{8}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Liquid Neural Networks}{8}{section.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Continuous-Time Dynamical Systems/Differential Equations}{8}{subsection.2.1.1}\protected@file@percent }
\newlabel{eq:1}{{2.1}{8}{Continuous-Time Dynamical Systems/Differential Equations}{equation.2.1.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}LNN Training}{9}{subsection.2.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}LNN Inference}{9}{subsection.2.1.3}\protected@file@percent }
\citation{chahineRobustFlightNavigation2023}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.4}Advantages of LNNs}{10}{subsection.2.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.4.a}Temporal Modelling}{10}{subsubsection.2.1.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.4.b}Adaptability}{10}{subsubsection.2.1.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.4.c}Efficiency}{10}{subsubsection.2.1.4.3}\protected@file@percent }
\citation{henriksenEfficientNeuralNetwork}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.4.d}Stability}{11}{subsubsection.2.1.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Neural Network Verification}{11}{section.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}The Verification Problem}{11}{subsection.2.2.1}\protected@file@percent }
\newlabel{verification_def}{{2.2.1}{11}{The Verification Problem}{subsection.2.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Motivation}{11}{subsection.2.2.2}\protected@file@percent }
\citation{WhatRecurrentNeural2021}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Recurrent Neural Networks}{12}{subsection.2.2.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Feedforward (traditional) vs. Recurrent Neural Networks}}{12}{figure.2.1}\protected@file@percent }
\newlabel{fig:example_image}{{2.1}{12}{Feedforward (traditional) vs. Recurrent Neural Networks}{figure.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.4}Robustness Verification for Recurrent Neural Networks}{12}{subsection.2.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.5}Symbolic and Interval Propagation Methods}{13}{subsection.2.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.5.a}SIP (Symbolic Interval Propagation)}{13}{subsubsection.2.2.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Steps in SIP:}{13}{section*.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Advantages for Liquid Neural Networks}{14}{section*.5}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Practical Considerations}{14}{section*.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.5.b}CROWN (Certified Robustness to Weight Perturbations)}{14}{subsubsection.2.2.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Mathematical Framework}{14}{section*.7}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Bounding Nonlinearities}{14}{section*.8}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Output Certification}{14}{section*.9}\protected@file@percent }
\citation{zhangEfficientNeuralNetwork2018}
\@writefile{toc}{\contentsline {paragraph}{Application to Neural ODEs}{15}{section*.10}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Practical Implementation}{15}{section*.11}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.5.c}Lipschitz-Based Methods}{15}{subsubsection.2.2.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Mathematical Foundation}{15}{section*.12}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Estimation of the Lipschitz Constant}{15}{section*.13}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Verification Applications}{16}{section*.14}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Practical Implementation}{16}{section*.15}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Liquid Neural Network Design and Implementation}{17}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Design Overview}{17}{section.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Wiring and Connectivity}{17}{section.3.2}\protected@file@percent }
\@writefile{lol}{\contentsline {lstlisting}{\numberline {3.1}Simplified RandomWiring class}{18}{lstlisting.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.3}LTC Neuron Dynamics}{18}{section.3.3}\protected@file@percent }
\@writefile{lol}{\contentsline {lstlisting}{\numberline {3.2}Simplified LTC neuron forward method}{19}{lstlisting.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Network Architecture}{19}{section.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Design Considerations and Tradeoffs:}{19}{section*.16}\protected@file@percent }
\@writefile{lol}{\contentsline {lstlisting}{\numberline {3.3}Structure of the LTCRNN module}{20}{lstlisting.3.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces High-level structure of the LTC-RNN. Each time step processes input via a shared LTC cell, with the membrane state passed forward recursively.}}{20}{figure.3.1}\protected@file@percent }
\newlabel{fig:ltc_rnn_architecture}{{3.1}{20}{High-level structure of the LTC-RNN. Each time step processes input via a shared LTC cell, with the membrane state passed forward recursively}{figure.3.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Simplified computational path of a single LIF neuron. Conductance-based synaptic integration is performed iteratively over time.}}{21}{figure.3.2}\protected@file@percent }
\newlabel{fig:lif_inner_dynamics}{{3.2}{21}{Simplified computational path of a single LIF neuron. Conductance-based synaptic integration is performed iteratively over time}{figure.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces LIF Neuron Layer in the LTC network. Sensory and recurrent inputs are processed through parameterised synapses and integrated using an ODE solver.}}{21}{figure.3.3}\protected@file@percent }
\newlabel{fig:lif_layer_ode}{{3.3}{21}{LIF Neuron Layer in the LTC network. Sensory and recurrent inputs are processed through parameterised synapses and integrated using an ODE solver}{figure.3.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Training Configuration (and dataset)}{21}{section.3.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Architecture of the Liquid Time-Constant Network (LNN). Inputs project through learned sensory filters to a sparsely recurrent Liquid Layer of LIF neurons. Dynamics are integrated using an internal ODE solver with unfolding. Final outputs are read from a low-dimensional projection.}}{22}{figure.3.4}\protected@file@percent }
\newlabel{fig:lnn_architecture}{{3.4}{22}{Architecture of the Liquid Time-Constant Network (LNN). Inputs project through learned sensory filters to a sparsely recurrent Liquid Layer of LIF neurons. Dynamics are integrated using an internal ODE solver with unfolding. Final outputs are read from a low-dimensional projection}{figure.3.4}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {3.4}Simplified training loop for the LNN}{22}{lstlisting.3.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Internal structure of a single LIF neuron used in the Liquid Time-Constant Network. Inputs undergo non-linear transformations based on trainable $\mu $ and $\sigma $, with the resulting activations integrated using biophysical parameters such as leak conductance ($g_\text  {leak}$), membrane capacitance ($C_m$), and reversal potentials ($E_\text  {rev}$).}}{23}{figure.3.5}\protected@file@percent }
\newlabel{fig:lif_neuron_detailed}{{3.5}{23}{Internal structure of a single LIF neuron used in the Liquid Time-Constant Network. Inputs undergo non-linear transformations based on trainable $\mu $ and $\sigma $, with the resulting activations integrated using biophysical parameters such as leak conductance ($g_\text {leak}$), membrane capacitance ($C_m$), and reversal potentials ($E_\text {rev}$)}{figure.3.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.6}Training Behaviour}{23}{section.3.6}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Trajectory Loss Curves}{24}{section*.17}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Training and validation loss over epochs.}}{24}{figure.3.6}\protected@file@percent }
\newlabel{fig:lnn_loss}{{3.6}{24}{Training and validation loss over epochs}{figure.3.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces Training and validation loss over epochs.}}{24}{figure.3.7}\protected@file@percent }
\newlabel{fig:lnn_loss_zoomed}{{3.7}{24}{Training and validation loss over epochs}{figure.3.7}{}}
\@writefile{toc}{\contentsline {paragraph}{Qualitative Evaluation}{24}{section*.18}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces LLN predicted vs true spiral trajectory at epoch 1, on denormalised training (and validation) spiral}}{25}{figure.3.8}\protected@file@percent }
\newlabel{fig:lnn_training_validation_spiral_epoch_1}{{3.8}{25}{LLN predicted vs true spiral trajectory at epoch 1, on denormalised training (and validation) spiral}{figure.3.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.9}{\ignorespaces LLN predicted vs true spiral trajectory at epoch 400, on denormalised training (and validation) spiral}}{25}{figure.3.9}\protected@file@percent }
\newlabel{fig:lnn_training_validation_spiral_epoch_400}{{3.9}{25}{LLN predicted vs true spiral trajectory at epoch 400, on denormalised training (and validation) spiral}{figure.3.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.10}{\ignorespaces LLN predicted vs true spiral trajectory at epoch 2000, on denormalised training (and validation) spiral}}{26}{figure.3.10}\protected@file@percent }
\newlabel{fig:lnn_training_validation_spiral_epoch_2000}{{3.10}{26}{LLN predicted vs true spiral trajectory at epoch 2000, on denormalised training (and validation) spiral}{figure.3.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.1}Inference}{26}{subsection.3.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Comparative Models}{28}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Introduction to Baseline Models}{28}{section.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Temporal Convolutional Network (TCN)}{28}{section.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Overview and Motivation}{28}{subsection.4.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Theoretical Background}{28}{subsection.4.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.3}Model Architecture}{29}{subsection.4.2.3}\protected@file@percent }
\@writefile{lol}{\contentsline {lstlisting}{\numberline {4.1}Simplified TCN architecture}{29}{lstlisting.4.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Temporal Convolutional Network (TCN) architecture with 3 residual blocks and exponentially increasing dilation. Each block contains two dilated convolutions with dropout, ReLU, and optional skip connection.}}{29}{figure.4.1}\protected@file@percent }
\newlabel{fig:tcn_architecture}{{4.1}{29}{Temporal Convolutional Network (TCN) architecture with 3 residual blocks and exponentially increasing dilation. Each block contains two dilated convolutions with dropout, ReLU, and optional skip connection}{figure.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.4}Training Configuration}{30}{subsection.4.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.5}Performance and Behaviour}{30}{subsection.4.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.6}Design Considerations}{30}{subsection.4.2.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Long Short-Term Memory Network (LSTM)}{30}{section.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Background and Rationale}{30}{subsection.4.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}LSTM Cell Mechanics}{30}{subsection.4.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.3}Model Implementation}{30}{subsection.4.3.3}\protected@file@percent }
\@writefile{lol}{\contentsline {lstlisting}{\numberline {4.2}Simplified LSTM model structure}{31}{lstlisting.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.4}Training Configuration}{31}{subsection.4.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.5}Training Observations}{31}{subsection.4.3.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Architecture of the LSTM model. The left shows residual-enhanced flow through a 2-layer LSTM, while the right shows the LSTM unrolled across time with hidden and cell state transitions.}}{31}{figure.4.2}\protected@file@percent }
\newlabel{fig:lstm_architecture_final}{{4.2}{31}{Architecture of the LSTM model. The left shows residual-enhanced flow through a 2-layer LSTM, while the right shows the LSTM unrolled across time with hidden and cell state transitions}{figure.4.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Transformer Model}{31}{section.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Transformer Encoder Design}{32}{section*.20}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Model Architecture}{32}{section*.21}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Suitability for the Task}{32}{section*.23}\protected@file@percent }
\@writefile{lol}{\contentsline {lstlisting}{\numberline {4.3}Simplified Transformer architecture}{33}{lstlisting.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}Training Configuration}{33}{subsection.4.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.2}Performance and Behaviour}{33}{subsection.4.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.3}Design Considerations}{33}{subsection.4.4.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Architecture of the Transformer encoder used}}{34}{figure.4.3}\protected@file@percent }
\newlabel{fig:transformer_encoder_diagram}{{4.3}{34}{Architecture of the Transformer encoder used}{figure.4.3}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Adversarial Attack Methodology}{35}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Introduction to Adversarial Attacks}{35}{section.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Fast Gradient Sign Method (FGSM)}{35}{section.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}Mathematical Formulation}{35}{subsection.5.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}Implementation Details}{35}{subsection.5.2.2}\protected@file@percent }
\@writefile{lol}{\contentsline {lstlisting}{\numberline {5.1}FGSM adversarial attack implementation}{36}{lstlisting.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.3}Evaluation and Observations}{36}{subsection.5.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Projected Gradient Descent (PGD)}{36}{section.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.1}Mathematical Formulation}{36}{subsection.5.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.2}Implementation Details}{36}{subsection.5.3.2}\protected@file@percent }
\@writefile{lol}{\contentsline {lstlisting}{\numberline {5.2}PGD Attack Loop (Simplified)}{36}{lstlisting.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.3}Performance and Model Responses}{37}{subsection.5.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.4}Design Choices}{37}{subsection.5.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.5}DeepFool-Inspired Directional Attack}{37}{subsection.5.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.6}Theoretical Basis}{37}{subsection.5.3.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.7}Implementation Summary}{37}{subsection.5.3.7}\protected@file@percent }
\@writefile{lol}{\contentsline {lstlisting}{\numberline {5.3}Directional (DeepFool-like) Gradient Attack}{37}{lstlisting.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.8}Model Comparisons and Observations}{38}{subsection.5.3.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.9}Design Considerations}{38}{subsection.5.3.9}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Simultaneous Perturbation Stochastic Approximation (SPSA)}{38}{section.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.1}Mathematical Formulation}{38}{subsection.5.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.2}Implementation and Design Choices}{38}{subsection.5.4.2}\protected@file@percent }
\@writefile{lol}{\contentsline {lstlisting}{\numberline {5.4}Simplified SPSA implementation}{39}{lstlisting.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.3}Empirical Performance Across Models}{39}{subsection.5.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.4}Reflections on Robustness}{39}{subsection.5.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.5}Time-Warping Attack}{39}{section.5.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.1}Conceptual Basis}{39}{subsection.5.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.2}Mathematical Formulation}{39}{subsection.5.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.3}Implementation Strategy}{40}{subsection.5.5.3}\protected@file@percent }
\@writefile{lol}{\contentsline {lstlisting}{\numberline {5.5}Example Time-Warping Attack Function}{40}{lstlisting.5.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.4}Results and Model Sensitivity}{40}{subsection.5.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.5}Design Choices}{40}{subsection.5.5.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.6}Continuous-Time Perturbation Attack}{40}{section.5.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6.1}Motivation}{40}{subsection.5.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6.2}Formulation and Mechanism}{41}{subsection.5.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6.3}Implementation Details}{41}{subsection.5.6.3}\protected@file@percent }
\@writefile{lol}{\contentsline {lstlisting}{\numberline {5.6}Continuous-Time Perturbation Injection}{41}{lstlisting.5.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6.4}Model-Specific Responses}{41}{subsection.5.6.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6.5}Design Rationale}{41}{subsection.5.6.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.7}Summary of Attack Design and Implementation Decisions}{42}{section.5.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.7.1}Attack Categories and Coverage}{42}{subsection.5.7.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces Overview of attack types and model sensitivities.}}{42}{table.5.1}\protected@file@percent }
\newlabel{tab:attack_summary}{{5.1}{42}{Overview of attack types and model sensitivities}{table.5.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.7.2}Implementation Consistency}{42}{subsection.5.7.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.7.3}Design Considerations}{42}{subsection.5.7.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.7.4}Interpretation of Results}{42}{subsection.5.7.4}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Bound Certification (Auto Lirpa)}{43}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Evaluation}{44}{chapter.7}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}Quantitative Evaluation Metrics and Comparison}{44}{section.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.1}Evaluation Metrics}{44}{subsection.7.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.2}Aggregate Results}{45}{subsection.7.1.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {7.1}{\ignorespaces Average degradation and deviation metrics across all attack types.}}{45}{table.7.1}\protected@file@percent }
\newlabel{tab:agg_metrics}{{7.1}{45}{Average degradation and deviation metrics across all attack types}{table.7.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.3}Attack-Specific Breakdowns}{45}{subsection.7.1.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {7.2}{\ignorespaces Degradation ratios across models for each attack. Lower is better.}}{45}{table.7.2}\protected@file@percent }
\newlabel{tab:attack_results_degradation}{{7.2}{45}{Degradation ratios across models for each attack. Lower is better}{table.7.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {7.3}{\ignorespaces ?}}{45}{table.7.3}\protected@file@percent }
\newlabel{tab:attack_results_deviation}{{7.3}{45}{?}{table.7.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {7.4}{\ignorespaces ?}}{46}{table.7.4}\protected@file@percent }
\newlabel{tab:attack_results_sensitivity}{{7.4}{46}{?}{table.7.4}{}}
\@writefile{toc}{\contentsline {paragraph}{Interpretation}{46}{section*.28}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Interpretation}{46}{section*.29}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7.2}Qualitative Evaluation and Visual Analysis}{46}{section.7.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.1}Visualisation Methodology}{46}{subsection.7.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.2}LSTM Responses}{46}{subsection.7.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.3}TCN Responses}{47}{subsection.7.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.4}LNN Responses}{47}{subsection.7.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.5}Comparative Failure Modes}{47}{subsection.7.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.6}Phase Drift and Spiral Collapse}{47}{subsection.7.2.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.7}Interpretive Summary}{47}{subsection.7.2.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7.3}Comparative Discussion of Model Robustness}{47}{section.7.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3.1}Summary of Behaviour Under Attack}{47}{subsection.7.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3.2}Architectural Trade-offs}{48}{subsection.7.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3.3}Robustness by Attack Type}{48}{subsection.7.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3.4}Implications for Deployment}{48}{subsection.7.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3.5}Conclusion}{48}{subsection.7.3.5}\protected@file@percent }
\bibstyle{vancouver}
\bibdata{bibs/fyp}
\@writefile{toc}{\contentsline {chapter}{\numberline {8}Conclusion}{49}{chapter.8}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\bibcite{chahineRobustFlightNavigation2023}{1}
\bibcite{hasaniLiquidTimeconstantNetworks2021}{2}
\bibcite{tedxtalksLiquidNeuralNetworks2023}{3}
\bibcite{henriksenEfficientNeuralNetwork}{4}
\bibcite{WhatRecurrentNeural2021}{5}
\bibcite{zhangEfficientNeuralNetwork2018}{6}
\@writefile{toc}{\contentsline {chapter}{\numberline {9}Declaration}{51}{chapter.9}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\gdef \@abspage@last{51}
